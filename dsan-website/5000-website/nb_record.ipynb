{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Record Data\n",
    "\n",
    "Within this tab I will provide my code, explanation and analysis for my naive bayes gaussian machine learning model. I ultimately decided to add a seventh variable to my dataset. This variable is the percentage of policy in a country in a specific year specifically relating to ocean sustainability. I had to clean and tidy this data. You can find this [here](/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/codes/02-data-cleaning/cleaning_policy.ipynb).\n",
    "\n",
    "This model aims to explore whether specific variables are good indicators of the extent to which policies relate to the ocean. It can help identify which aspects or attributes of policies are more strongly correlated with ocean-related policies and which are not. If the model performs well, the findings could have the ability inform data-driven decision-making in policy development specifically with regard to ocean sustainability and conservation efforts.\n",
    "\n",
    "The analysis has the ability to uncover trends or patterns in policy data that can be used for policy assessment, trend analysis, and making informed recommendations.\n",
    "\n",
    "## Initial Gaussian Naive Bayes \n",
    "\n",
    "### Prepping Data for Model\n",
    "\n",
    "Within this code chunk, the necessary libraris are installed, the data is imported, all columns are set to integers and the country columns is encoded in order for the model to run correctly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Loading Merged Data\n",
    "nb_record = pd.read_csv(\"/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/data/01-modified-data/nb_record.csv\")\n",
    "\n",
    "# Encode the \"Country\" column using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "nb_record['Country'] = label_encoder.fit_transform(nb_record['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Feature and Target Variables\n",
    "\n",
    "**Features** - Marine Protected Area, Inventions, Instruments, Aquaculture Production and Fishing Exports\n",
    "\n",
    "**Target** - Percentage of Policy out of all policy in a year relating to ocean sustainability. I binned these values into five bins. These bins are 0-17, 18-36, 37-54, 55 - 72, 73 - 87. \n",
    "\n",
    "I did this to help simplify and interpret my model. For example, if a country in a specific year has only 5% of all their policy relating to ocean sustainability then the value will be put in bin 0.\n",
    "\n",
    "The code below splits the data into feature and target variables as well as splits the data into training, testing and validation sets. I have commented on the code to display what each line does as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#Creating bins for target - 5 different bins\n",
    "y = nb_record['Value']\n",
    "bin_edges = [0, 18, 36, 54, 72, 87]\n",
    "y_binned = pd.cut(y, bins=bin_edges, labels=False, include_lowest=True)\n",
    "\n",
    "# X is all features besides Value\n",
    "X = nb_record.drop(['Value'], axis=1)\n",
    "\n",
    "# Split the data into training and the remaining data\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X, y_binned, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the remaining data into testing and validation sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_remaining, y_remaining, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Gaussian Naive Bayes Classifier \n",
    "\n",
    "As stated earlier I am using a gaussian naive bayes classifer to complete this model. I have access to this from the library sklearn.naive_bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Training classifier using training data \n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions and Evaluating Performance\n",
    "\n",
    "Some helpful definitions to know when viewing this part of the modeling process are:\n",
    "\n",
    "**Accuracy:** A performance metric used to evaluate the accuracy of a machine learning model on a test dataset\n",
    "\n",
    "**Precision:** Precision = True Positives (TP) / (False Positives (FP) + True Positives (TP))\n",
    "\n",
    "**Recall:** Recall = True Positives (TP) / (False Negatives (FN) + True Positives (TP))\n",
    "\n",
    "**F1:** Combines precision and recall. F1 = 2 × (Precision+Recall) / (Precision×Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5207756232686981\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.43      0.60       290\n",
      "           1       0.21      0.79      0.33        24\n",
      "           2       0.11      0.83      0.20        12\n",
      "           3       0.50      0.86      0.63         7\n",
      "           4       0.72      1.00      0.84        28\n",
      "\n",
      "    accuracy                           0.52       361\n",
      "   macro avg       0.50      0.78      0.52       361\n",
      "weighted avg       0.86      0.52      0.58       361\n",
      "\n",
      "Testing Accuracy: 0.4351851851851852\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.37      0.53        84\n",
      "           1       0.27      0.54      0.36        13\n",
      "           2       0.03      1.00      0.07         1\n",
      "           3       0.44      0.67      0.53         6\n",
      "           4       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.44       108\n",
      "   macro avg       0.41      0.71      0.40       108\n",
      "weighted avg       0.80      0.44      0.51       108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.40059015e-01, 6.20769036e-01, 2.32054725e-01, 2.38616613e-03,\n",
       "        4.73105801e-03],\n",
       "       [9.11330611e-04, 1.23658396e-02, 9.86058060e-01, 5.10862715e-04,\n",
       "        1.53907191e-04],\n",
       "       [5.51560706e-02, 8.33551884e-01, 2.02445791e-07, 3.65430935e-02,\n",
       "        7.47487491e-02],\n",
       "       [4.19889840e-02, 5.27452829e-01, 2.69748514e-13, 3.19635760e-01,\n",
       "        1.10922427e-01],\n",
       "       [1.57071654e-01, 4.45159543e-01, 3.94093016e-01, 2.77159035e-03,\n",
       "        9.04197025e-04],\n",
       "       [9.99986400e-01, 1.35373052e-05, 5.90092813e-29, 1.16032598e-17,\n",
       "        6.22498014e-08],\n",
       "       [4.83046820e-02, 8.83794490e-02, 8.62787419e-01, 2.69749400e-04,\n",
       "        2.58700541e-04],\n",
       "       [9.79079856e-02, 1.34444554e-01, 1.52569334e-06, 7.64435654e-01,\n",
       "        3.21028027e-03],\n",
       "       [5.90704393e-04, 2.02827078e-03, 9.96193986e-01, 1.16545350e-03,\n",
       "        2.15853155e-05],\n",
       "       [1.31887557e-02, 8.06003299e-02, 9.04201100e-01, 1.56237719e-03,\n",
       "        4.47437424e-04]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "# Predictions on the training set / Model's performance on the training set / Classification Report\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", accuracy_train)\n",
    "classification_report_train = classification_report(y_train, y_train_pred)\n",
    "print(\"Training Classification Report:\\n\", classification_report_train)\n",
    "\n",
    "# Predictions on the testing set / Models performance on testing set / Classification Report\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Testing Accuracy:\", accuracy_test)\n",
    "classification_report_test = classification_report(y_test, y_test_pred)\n",
    "print(\"Testing Classification Report:\\n\", classification_report_test)\n",
    "\n",
    "gnb.predict_proba(X_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6170212765957447\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.59      0.75        37\n",
      "           1       0.40      0.57      0.47         7\n",
      "           2       0.11      1.00      0.20         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.38      0.63      0.40        47\n",
      "weighted avg       0.87      0.62      0.69        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kendallgilbert/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kendallgilbert/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kendallgilbert/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "# Predictions on the validation set /  Model's performance on the validation set / Classificiation Report\n",
    "y_val_pred = gnb.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", accuracy_val)\n",
    "classification_report_val = classification_report(y_val, y_val_pred)\n",
    "print(\"Validation Classification Report:\\n\", classification_report_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these numbers mean?\n",
    "\n",
    "The training accuracy is 52%, the testing accuracy is 43% and the validation accuracy is 61%. This means that there is room for improvement that can be done through feature selection. \n",
    "\n",
    "Another number to pay attention to is the F1 score which combines precision and recall. The F1 weighted average for the training set is 58, 51 for the testing set and 69 for the validation set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Knowing that our accuracy is not as high as we would prefer, we can resort to feature selection!\n",
    "\n",
    "The primary objective of feature selection is identifying and choosing the most relevant features from the data set for the given task. I used feature selection to improove the overall accuracy of my Naive Bayes model. Feature selection returns a subset of original features. You can learn more about feature selection under the feature selection menu or [here](FS.ipynb).\n",
    "\n",
    "## Gaussian Naive Bayes Classifier (Feature Selected Data)\n",
    "\n",
    "In an attempt to figure out what features improove accuracy, I manually tested the combinations of a features as X. I ended up figuring out that dropping Aquaculture Production and Fishing Exports improove the accuracy of this model. \n",
    "\n",
    "Within the code below, you will notice that I have done the exact same process as above but dropped two features. You will see that the accuracy increases! \n",
    "\n",
    "Note* I did not include in depth comments on this process again as you can see them above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7811634349030471\n",
      "Testing Accuracy: 0.7037037037037037\n",
      "Validation Accuracy: 0.7872340425531915\n",
      "Training F1 Score: 0.8307245987070051\n",
      "Testing F1 Score: 0.750756989719462\n",
      "Validation F1 Score: 0.8058261232337525\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "from sklearn.metrics import f1_score\n",
    "y = nb_record['Value']\n",
    "bin_edges = [0, 18, 36, 54, 72, 87]\n",
    "y_binned = pd.cut(y, bins=bin_edges, labels=False, include_lowest=True)\n",
    "X = nb_record.drop(['Value', 'Aqua Production (Millions)', 'Fishing Exports (Millions)'], axis=1)\n",
    "\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X, y_binned, test_size=0.3, random_state=42) #train_test_split function from the scikit-learn library to split your data into training and remaining sets for classification\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_remaining, y_remaining, test_size=0.3, random_state=42)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model's performance on the training set\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", accuracy_train)\n",
    "\n",
    "# Predictions on the testing set / Calculate the accuracy for the test set\n",
    "\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "accuracy_test_fs = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Testing Accuracy:\", accuracy_test_fs)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = gnb.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy for the validation set\n",
    "accuracy_val_fs = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", accuracy_val_fs)\n",
    "\n",
    "f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "f1_val = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "print(\"Training F1 Score:\", f1_train)\n",
    "print(\"Testing F1 Score:\", f1_test)\n",
    "print(\"Validation F1 Score:\", f1_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As displayed, the accuracy and F1 score for training, testing and validation ALL increased. This is a direct result of getting rid of two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [108, 47]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/nb/nb_record.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/nb/nb_record.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/nb/nb_record.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Calculate the confusion matrix\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/nb/nb_record.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, y_val_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/nb/nb_record.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Plot the confusion matrix as a heatmap\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kendallgilbert/dsan-5000-project-kendallgilbert180/dsan-website/5000-website/nb/nb_record.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m6\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [108, 47]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_val_pred)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## further Analysis on Naive Bayes\n",
    "\n",
    "**Describe how the trained model is tested on the testing dataset.**\n",
    "\n",
    "Within this tab it can be understood that the trained model is tested on the testing set. This is the basis of machine learning. We want to train the model first before it is actually implemented onto the testing dataset. \n",
    "\n",
    "**What is overfitting and underfitting**\n",
    "\n",
    "Underfitting is when the model does not fit the data well.  \n",
    "\n",
    "Overitting is when the model fits the data too well. \n",
    "\n",
    "Within the first round of the gaussian naive bayes model, the \n",
    "\n",
    "e.g. what is the output that you generate. What does the output mean? What does it tell you about your data? \n",
    "\n",
    "**Does the model do a good job of predicting test data?**\n",
    "\n",
    "As shown by the testing accuracy of 70%, we can infer that the model does an alright job predicting test data. It could be better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Overall, this tab walks readers through a naive bayes classification example. This example works specifically with the features Marine Protected Area, Inventions, Instruments, Aquaculture Production and Fishing Exports. The target is the percentage of policy out of all policy in a year relating to ocean sustainability. This model has 70% accuracy. \n",
    "\n",
    "So how can this model helps us? \n",
    "\n",
    "- This model learns a pattern that we could extrapolate to other countries that we only have specific features for. \n",
    "- This model can help researchers understand what features have had an impact on ocean policy in the past therefore they could focus on what other countries completed in the past in an attempt to lead to more ocean policy. \n",
    "- Could inform policy makers with what features have impacted policy in other states in an attempt to implement to share specific findings data-driven decision-making.\n",
    "- This model shows which countries are committed to policy and the features that have impacted this commitment. \n",
    "\n",
    "Given this naive Bayes model, we have the ability to make predictions for new data using Bayes theorem. When given a data point X, what is the probability of X belonging to some class C?\n",
    "\n",
    "If we wanted to see the probability of Country X being in bin 1 with features _____ . We implement the code - \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
