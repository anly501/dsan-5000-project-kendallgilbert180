{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Naive Bayes?\n",
    "\n",
    "Naive Bayes classification is a supervised machine learning algorithm used for classification tasks. This form of machine learning is based on the Bayes Theorem. \n",
    "\n",
    "Using Bayes theorem, we can find the probability of A happening, given that B has occurred. \n",
    "\n",
    "In a classification, Naive Bayes has the ability to predict the probability of a particular class or label based on observed features or attributes. \n",
    "\n",
    "The \"naive\" assumption in Naive Bayes is that features are conditionally independent given the class label. Naive Bayes assumes that the presence or absence of one feature is unrelated to the presence or absence of other features.\n",
    "\n",
    "There are different variants of Naive Bayes and each is used for different circumstances. The different variants include Gaussian, Multinomial and Bernoulli. Gaussian assumes that the features in the dataset follow a normal distribution. It is typically used in NLP or sentiment analysis. Multinomial is used for discrete data and could be used for modeling text classification. Finally, Bernoulli is used when the data is binary or boolean.\n",
    "\n",
    "## Naive Bayes for my Project\n",
    "\n",
    "\n",
    "I will complete Naive Bayes on text data as well as record data. \n",
    "\n",
    "For record data, to explore whether specific variables are good indicators of the extent to which policies relate to the ocean. I will employ the following features for classification: marine protected area (MPA), fishing exports, aquaculture production, environment-technology inventions, and policy instruments. I will use the variant **Guassian**.\n",
    "\n",
    "For text data, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Naive Bayes\n",
    "\n",
    "Data needs to be separated into training, validation and testing sets.\n",
    "\n",
    "*Why is data split into training, validation and testing sets?*\n",
    "\n",
    "**Training Set:** This is the portion of the dataset used to train your machine learning model. The model learns patterns, relationships, and the underlying structure of the data from the training set.\n",
    "\n",
    "**Testing Set:** The testing set is used to evaluate the model's performance after it has been trained. It serves as an independent dataset to assess how well the model generalizes to unseen data. The testing set can estimate the model's accuracy, precision, recall, F1-score, etc.\n",
    "\n",
    "**Validation Set:** The validation set is used for model selection and hyperparameter tuning. It allows you to experiment with different model architectures, hyperparameters, and techniques to optimize your model's performance. You assess the model's performance on the validation set and make adjustments as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Feature Selection is a crucial component of data science, especially when dealing with large data sets. The primary objective of feature selection is identifying and choosing the most relevant features from the data set for the given task. \n",
    "\n",
    "**Record Data Feature Selection**\n",
    "\n",
    "Navigate to the link [here](FS.html) to learn more about feature selection for the record data and how it was completed within this project. \n",
    "\n",
    "**Text Data Feature Selection**\n",
    "\n",
    "Navigate to the link [here](fs_text.html) to learn more about feature selection for the text data and how it was completed within this project. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
