{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "format: html\n",
    "bibliography: project_reference.bib\n",
    "---\n",
    "\n",
    "## PCA Dimensionality Reduction\n",
    "\n",
    "## What is PCA?\n",
    "\n",
    "PCA stands for principal component analysis. It is a machine learning technique that is used to reduce the dimensionality of large datasets. The goal of PCA is to reduce the number of variables while preserving as much information as possible. [@noauthor_principal_nodate]\n",
    "\n",
    "PCA can be broken down into five steps: \n",
    "\n",
    "1) Standization\n",
    "2) Covariance Matrix Computation\n",
    "3) Computing the eigenvectors and eigenvalues to identify principal comonents\n",
    "4) Feature Vectors \n",
    "5) Recasting data among principal component axis\n",
    "\n",
    "To learn more about PCA in depth this is a good resource [here](https://builtin.com/data-science/step-step-explanation-principal-component-analysis).\n",
    "\n",
    "\n",
    "\n",
    "## Applying PCA to Data\n",
    "\n",
    "## Determining Optimal # of Principal Components\n",
    "\n",
    "## Visualization using PCA.\n",
    "\n",
    "## Analyzing / Interpreting Results\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
