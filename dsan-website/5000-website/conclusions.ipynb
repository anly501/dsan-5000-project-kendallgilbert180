{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Conclusions\n",
    "format: html\n",
    "bibliography: project_reference.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "Within this project I had the opportunity to complete an abundance of data science techniques in an attempt to learn more about ocean sustainability. The main objective of this project was to answer questions like:\n",
    "\n",
    "\n",
    "- What is the Importance of Ocean Sustainability?\n",
    "- What Negative Impacts Do Humans Have on Ocean Sustainability?\n",
    "- What Is Currently Being Done for Ocean Sustainability?\n",
    "\n",
    "\n",
    "I believe that I was successful in answering these questions. Throughout this conclusion I will elaborate on my findings. I have also analyzed and elaborated on my findings in more depth within each tab.\n",
    "\n",
    "\n",
    "## Data Gathering\n",
    "\n",
    "\n",
    "I collected a majority of my data from OECD - the Organization for Economic Cooperation and Development. I obtained six datasets from this resource regarding marine protected area, fishing exports, policy instruments, inventions, percentage of policy relating to ocean sustainability and aquaculture production. Furthermore I gathered text data from a Reddit API. This API allowed me to gather posts regarding ocean sustainability and ocean pollution. You can view my data gathering steps [here](gathering.ipynb).\n",
    "\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "\n",
    "After gathering my data I then had to clean my data. Data cleaning takes a significant amount of time. Within this process I cleaned and tidied the data as well as merged all datasets that came from OECD. You can view my data cleaning steps [here](cleaning.ipynb).\n",
    "\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "Next, I completed EDA on my data. I did both univariate and multivariate EDA. The findings within this section helped set me up for success within future steps of this process. First, within the univariate EDA I was able to understand trends within my data. For example I learned:\n",
    "\n",
    "- The number of environmental technology inventions increased around 2010 and since then has decreased\n",
    "- The number of policy instruments are slowly increasing each year\n",
    "- Aquaculture Production is increasing\n",
    "- Aquaculture production is highest in the United States, New Zealand and Australia\n",
    "- Marine Protected Area is steadily increasing each year.\n",
    "- Marine Protected Area is highest in China\n",
    "- The predicted average tonnes of plastic is steadily increasing until 2060\n",
    "\n",
    "\n",
    "It was also beneficial to look at the five number summaries for each variable to start taking note of any outliers or strange numbers.\n",
    "\n",
    "\n",
    "Within the multivariate EDA I explored correlations and relationships between variables. I did this through the use of Pearson correlation and scatter plots. From this EDA I was able to understand that the correlations within my dataset were relatively low besides the strong correlation between Marine Protected Area and Fishing Exports.\n",
    "\n",
    "\n",
    "Overall, EDA is a crucial step in the data science process that helped set my project up for success. I learned about my data which allowed me to successfully complete my models in the future. EDA helped me explore questions like what is currently being done to help ocean sustainability, the correlation between ocean sustainability movements and how sustainability is important to marine life and the wellness of communities. It also allows us to infer what will happen if sustainability is ignored.\n",
    "\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "\n",
    "The first machine learning model we completed was Naive Bayes. I completed Naive Bayes on my record data as well as my text data.\n",
    "\n",
    "\n",
    "My Naive Bayes model on record data aimed to explore whether specific variables are good indicators of the extent to which policies relate to the ocean. The model can help identify which aspects or attributes of policies are more strongly correlated with ocean-related policies and which are not. If the model performed well, the findings could have the ability to inform data-driven decision-making in policy development specifically with regard to ocean sustainability and conservation efforts. My model had a decent accuracy score at 70%. This model has the ability to help researchers find patterns, understand feature impact, and use it as a resource when coming up with policy and identifying committed countries.\n",
    "\n",
    "\n",
    "Furthermore, I completed a Naive Bayes model on text data. The ultimate goal of this model was to train a model to explore whether reddit posts regarding ocean sustainability and plastic pollution are good indicators of what sub reddit class they come from. This model had a 44% testing accuracy so it did not perform as well as the record data naive bayes. This model allows readers to gain insights into the prevalence of discussions related to ocean sustainability and plastic pollution across various subreddits as well as track trends and changes in the discussions related to ocean sustainability and plastic pollution over time.\n",
    "\n",
    "\n",
    "Naive Bayes helped me achieve my objective of answering questions like what is being done to help ocean sustainability and what is working more so than not.\n",
    "\n",
    "\n",
    "## Dimensionality Reduction\n",
    "\n",
    "\n",
    "I completed two forms of dimensionality reduction on my data - Principal Component Analysis and T-distributed Stochastic Neighbor Embedding. This dimensionality reduction ultimately helped me within clustering. PCA was able to help me view my seven dimensional data using two principal components. The plot showed me a lot of points close together as well as outliers. Additionally, I completed t-sne with three different perplexities. T-sne helped me understand how data points were close together in the higher dimension space. Overall, these dimensionality techniques told me that countries within my data set were similar in a high dimensional space and there are also countries that are not similar.\n",
    "\n",
    "\n",
    "Dimensionality reduction helps us infer that some countries are focused on ocean sustainability and others are not.\n",
    "\n",
    "\n",
    "## Clustering\n",
    "\n",
    "\n",
    "I clustered my data using three different methods of clustering - K-Means, DBSCAN and hierarchical. Each method of clustering allowed me to learn something new about my data. The optimal number of clusters for my data seemed to be 3. The three clusters obtained using DBSCAN clustering seem to have done the best job clustering my dimensionality reduced data. This is due to the fact that there are small distances between the points in clusters and large distances between the clusters.\n",
    "\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "\n",
    "I performed classification and regression decision trees and random forests on my data.\n",
    "\n",
    "\n",
    "I received a high accuracy using classification decision trees at 91% and the random forest accuracy was 96%. This decision tree was made to explore whether specific variables are good indicators of the extent to which policies relate to the ocean. The decision tree visualization allows us to see which features are most important in determining the sustainability category. This tree tells us that the most important feature when classifying which variables are good indicators of how policies relate to the ocean is the number of policy instruments.\n",
    "\n",
    "\n",
    "The regression decision tree was created to explore how well a model does at predicting the “value” which is the percentage of policy relating to ocean sustainability per year. The mean squared error was very large, although completing random forests decreased the mean squared error significantly.\n",
    "\n",
    "\n",
    "Overall, decision trees helped us understand import features like Marine Protected Area and policy instruments and their ability to help researchers predict how much a country will implement policy relating to ocean sustainability.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Wrap Up\n",
    "\n",
    "\n",
    "Overall, this project allowed me to dive into data from a wealth of countries regarding ocean sustainability. Data science tools allowed me to understand key things like what features have an impact on ocean sustainability, what will happen in the future if sustainability is ignored and what is currently being done that helps countries (that may be unknown).\n",
    "\n",
    "\n",
    "The most prominent features that have an impact on overall ocean sustainability throughout the world are marine protected areas, fishing exports and policy instruments. An increase in marine protected areas results in an increase in fishing exports. Furthermore, the amount of policy instruments (policy related to environment) also has an impact on ocean sustainability.\n",
    "\n",
    "\n",
    "Without the machine learning algorithms that I have implemented on this data throughout the course of this semester I would be unaware of what features need to be looked at more closely.\n",
    "\n",
    "\n",
    "I also was able to learn about what is currently being done and how it has the power to help a country's overall attempt at ocean sustainability.\n",
    "\n",
    "\n",
    "In the future, I would love to look more closely at marine protected area data and explore the impact marine protected area has on a countries overall sustainability.\n",
    "\n",
    "## Thank You!\n",
    "\n",
    "Special thanks to my DSAN Professors and friends who helped me successfully complete this project :) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
